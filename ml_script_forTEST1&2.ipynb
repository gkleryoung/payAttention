{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Function to parse the time from the timestamp string\n",
    "def parse_time(timestamp):\n",
    "    return timestamp.split()[0]\n",
    "\n",
    "# Function to parse the heart rate from the record\n",
    "def parse_heart_rate(record):\n",
    "    heart_rate_index = record.find('Heart Rate')\n",
    "    if heart_rate_index != -1:\n",
    "        return int(record[heart_rate_index + len('Heart Rate: '):].split()[0])\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to parse the conductivity value from the record\n",
    "def parse_conductivity(record):\n",
    "    return int(record.split()[-1])\n",
    "\n",
    "# Function to generate data points with average heart rate and conductivity readings for each second\n",
    "def generate_data_points1(data):\n",
    "    data_points = []\n",
    "    current_second = None\n",
    "    conductivities = []\n",
    "\n",
    "    for timestamp, value in data:\n",
    "        second = parse_time(timestamp)\n",
    "        if interval_1_start <= second <= interval_1_end or interval_2_start <= second <= interval_2_end :  # Check if the timestamp is within the specified intervals\n",
    "            if second != current_second:\n",
    "                if current_second is not None:\n",
    "            \n",
    "                    avg_conductivity = round(sum(conductivities) / len(conductivities), 1)\n",
    "                    data_points.append((timestamp, avg_conductivity, label_for_interval1(current_second)))\n",
    "                current_second = second\n",
    "                conductivities = []\n",
    "\n",
    "            heart_rate = parse_heart_rate(value)\n",
    "            if heart_rate is not None:\n",
    "                last_heart_rate = heart_rate\n",
    "            else:\n",
    "                conductivity = parse_conductivity(value)\n",
    "                conductivities.append(conductivity)\n",
    "\n",
    "    # Process the last second of data\n",
    "    if current_second is not None:\n",
    "        avg_conductivity = round(sum(conductivities) / len(conductivities), 1)\n",
    "        data_points.append((timestamp, avg_conductivity, label_for_interval1(current_second)))\n",
    "\n",
    "    return data_points\n",
    "\n",
    "def generate_data_points2(data):\n",
    "    data_points = []\n",
    "    current_second = None\n",
    "    conductivities = []\n",
    "\n",
    "    for timestamp, value in data:\n",
    "        second = parse_time(timestamp)\n",
    "        if interval_1_start_2 <= second <= interval_1_end_2 or interval_2_start_2 <= second <= interval_2_end_2 :  # Check if the timestamp is within the specified intervals\n",
    "            if second != current_second:\n",
    "                if current_second is not None:\n",
    "            \n",
    "                    avg_conductivity = round(sum(conductivities) / len(conductivities), 1)\n",
    "                    data_points.append((timestamp, avg_conductivity, label_for_interval2(current_second)))\n",
    "                current_second = second\n",
    "                conductivities = []\n",
    "\n",
    "            heart_rate = parse_heart_rate(value)\n",
    "            if heart_rate is not None:\n",
    "                last_heart_rate = heart_rate\n",
    "            else:\n",
    "                conductivity = parse_conductivity(value)\n",
    "                conductivities.append(conductivity)\n",
    "\n",
    "    # Process the last second of data\n",
    "    if current_second is not None:\n",
    "        avg_conductivity = round(sum(conductivities) / len(conductivities), 1)\n",
    "        data_points.append((timestamp, avg_conductivity, label_for_interval2(current_second)))\n",
    "\n",
    "    return data_points\n",
    "\n",
    "\n",
    "def generate_data_points3(data):\n",
    "    data_points = []\n",
    "    current_second = None\n",
    "    conductivities = []\n",
    "\n",
    "    for timestamp, value in data:\n",
    "        second = parse_time(timestamp)\n",
    "        if interval_1_start_3 <= second <= interval_1_end_3 or interval_2_start_3 <= second <= interval_2_end_3 :  # Check if the timestamp is within the specified intervals\n",
    "            if second != current_second:\n",
    "                if current_second is not None:\n",
    "            \n",
    "                    avg_conductivity = round(sum(conductivities) / len(conductivities), 1)\n",
    "                    data_points.append((timestamp, avg_conductivity, label_for_interval3(current_second)))\n",
    "                current_second = second\n",
    "                conductivities = []\n",
    "\n",
    "            heart_rate = parse_heart_rate(value)\n",
    "            if heart_rate is not None:\n",
    "                last_heart_rate = heart_rate\n",
    "            else:\n",
    "                conductivity = parse_conductivity(value)\n",
    "                conductivities.append(conductivity)\n",
    "\n",
    "    # Process the last second of data\n",
    "    if current_second is not None:\n",
    "        avg_conductivity = round(sum(conductivities) / len(conductivities), 1)\n",
    "        data_points.append((timestamp, avg_conductivity, label_for_interval3(current_second)))\n",
    "\n",
    "    return data_points\n",
    "\n",
    "# Function to determine the label based on the timestamp\n",
    "def label_for_interval1(timestamp):\n",
    "    interval_1_start = \"16:27:50\"\n",
    "    interval_1_end = \"16:37:50\"\n",
    "    interval_2_start = \"16:39:15\"\n",
    "    interval_2_end = \"16:49:15\"\n",
    "\n",
    "    if interval_1_start <= timestamp <= interval_1_end:\n",
    "        return 1\n",
    "    elif interval_2_start <= timestamp <= interval_2_end:\n",
    "        return 0\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def label_for_interval2(timestamp):\n",
    "    interval_1_start = \"15:26:00\"\n",
    "    interval_1_end = \"15:38:00\"\n",
    "    interval_2_start = \"15:39:00\"\n",
    "    interval_2_end = \"15:49:00\"\n",
    "\n",
    "    if interval_1_start <= timestamp <= interval_1_end:\n",
    "        return 1\n",
    "    elif interval_2_start <= timestamp <= interval_2_end:\n",
    "        return 0\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def label_for_interval3(timestamp):\n",
    "    interval_1_start_3 = \"16:18:00\"\n",
    "    interval_1_end_3 = \"16:20:00\"\n",
    "    interval_2_start_3 = \"16:20:15\"\n",
    "    interval_2_end_3 = \"16:22:00\"   \n",
    "\n",
    "    if interval_1_start_3 <= timestamp <= interval_1_end_3:\n",
    "        return 1\n",
    "    elif interval_2_start_3 <= timestamp <= interval_2_end_3:\n",
    "        return 0\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Read the CSV file\n",
    "data1 = []\n",
    "data2 = []\n",
    "data3 = []\n",
    "with open('arduinoToCsv/firstTestPani/outGSR.csv', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        timestamp = parse_time(row[0])\n",
    "        value = row[0]\n",
    "        \n",
    "        data1.append((timestamp, value))\n",
    "with open('arduinoToCsv/secondTestPani/outGSR-pani240321.csv', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        timestamp = parse_time(row[0])\n",
    "        value = row[0]\n",
    "        \n",
    "        data2.append((timestamp, value))\n",
    "\n",
    "with open('arduinoToCsv/thirdTestPani/skin_conductivity_data11apr.csv', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        timestamp = parse_time(row[0])\n",
    "        value = row[0]\n",
    "        \n",
    "        data3.append((timestamp, value))\n",
    "\n",
    "\n",
    "# Define the intervals\n",
    "interval_1_start = \"16:27:50\"\n",
    "interval_1_end = \"16:37:50\"\n",
    "interval_2_start = \"16:39:15\"\n",
    "interval_2_end = \"16:49:15\"\n",
    "\n",
    "\n",
    "#define interavls for second test\n",
    "interval_1_start_2 = \"15:26:00\"\n",
    "interval_1_end_2 = \"15:38:00\"\n",
    "interval_2_start_2 = \"15:39:00\"\n",
    "interval_2_end_2 = \"15:49:00\"\n",
    "\n",
    "#define interavls for third test\n",
    "interval_1_start_3 = \"16:18:00\"\n",
    "interval_1_end_3 = \"16:20:00\"\n",
    "interval_2_start_3 = \"16:20:15\"\n",
    "interval_2_end_3 = \"16:22:00\"\n",
    "\n",
    "# Generate data points with average heart rate and conductivity readings for each second\n",
    "data_points1 = generate_data_points1(data1)\n",
    "data_points2 = generate_data_points2(data2)\n",
    "data_points3 = generate_data_points3(data3)\n",
    "\n",
    "\n",
    "# Print the generated data points with labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297.96439267886853 25.768641960557293\n",
      "108.7465204236006 56.464952841477505\n",
      "209.95110132158587 60.7263047178912\n",
      "199.7728098873137 101.63457396620731\n"
     ]
    }
   ],
   "source": [
    "#normalise data\n",
    "\n",
    "#normalise\n",
    "import numpy as np\n",
    "\n",
    "values_1 = [value for (timestamp,value,label) in data_points1]\n",
    "values_2 = [value for (timestamp,value,label) in data_points2]\n",
    "values_3 = [value for (timestamp,value,label) in data_points3]\n",
    "v = values_1 + values_2 + values_3\n",
    "mean = np.mean(v)\n",
    "std = np.std(v)\n",
    "\n",
    "mean_1 = np.mean(values_1)\n",
    "std_1 = np.std(values_1)\n",
    "\n",
    "mean_2 = np.mean(values_2)\n",
    "std_2 = np.std(values_2)\n",
    "\n",
    "mean_3 = np.mean(values_3)\n",
    "std_3 = np.std(values_3)\n",
    "print(mean_1, std_1)\n",
    "print(mean_2, std_2)\n",
    "print(mean_3, std_3)\n",
    "print(mean, std)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264 264\n"
     ]
    }
   ],
   "source": [
    "# Create a new dataset by concatenating values within each 5-second interval\n",
    "length_of_data_points = 5\n",
    "dataset_1 = []\n",
    "\n",
    "labels_1= []\n",
    "for iter, data in enumerate(data_points1):\n",
    "    (timestamp, value, label) = data\n",
    "    value = round((value - mean_1)/ std_1, 3)\n",
    "    \n",
    "    if iter % length_of_data_points == 0:\n",
    "        new_data_point = [value]\n",
    "        if iter > 0:\n",
    "            labels_1.append(label_for_interval1(timestamp))\n",
    "    else:\n",
    "        new_data_point.append(value)\n",
    "        if len(new_data_point) == length_of_data_points:\n",
    "            dataset_1.append(new_data_point)\n",
    "    \n",
    "dataset_2 = []\n",
    "\n",
    "labels_2 = []\n",
    "for iter, data in enumerate(data_points2):\n",
    "    (timestamp, value, label) = data\n",
    "    value = round((value - mean_2)/ std_2, 3)\n",
    "    \n",
    "    if iter % length_of_data_points == 0:\n",
    "        new_data_point = [value]\n",
    "        if iter > 0:\n",
    "            labels_2.append(label_for_interval2(timestamp))\n",
    "    else:\n",
    "        new_data_point.append(value)\n",
    "        if len(new_data_point) == length_of_data_points:\n",
    "            dataset_2.append(new_data_point)\n",
    "    \n",
    "dataset_3 = []\n",
    "\n",
    "labels_3 = []\n",
    "for iter, data in enumerate(data_points3):\n",
    "    (timestamp, value, label) = data\n",
    "    value = round((value - mean_3)/ std_3, 3)\n",
    "    \n",
    "    if iter % length_of_data_points == 0:\n",
    "        new_data_point = [value]\n",
    "        if iter > 0:\n",
    "            labels_3.append(label_for_interval3(timestamp))\n",
    "    else:\n",
    "        new_data_point.append(value)\n",
    "        if len(new_data_point) == length_of_data_points:\n",
    "            dataset_3.append(new_data_point)\n",
    "  \n",
    "print(len(labels_2), len(dataset_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504\n"
     ]
    }
   ],
   "source": [
    "#combine data from both tests\n",
    "\n",
    "data = dataset_1 + dataset_3 #+ dataset_3\n",
    "labels = labels_1 + labels_3# + labels_3\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data, train_labels, test_labels= train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data_3, test_data_3, train_labels_3, test_labels_3= train_test_split(dataset_2, labels_2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOw with decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9702970297029703\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "max_depth = 2 # Set the maximum depth as desired\n",
    "tree_clf = DecisionTreeClassifier(max_depth=max_depth, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "tree_clf.fit(train_data, train_labels)\n",
    "\n",
    "# Predict on the test data\n",
    "predictions = tree_clf.predict(test_data)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.957345971563981\n"
     ]
    }
   ],
   "source": [
    "predictions = tree_clf.predict(train_data_3)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "accuracy = accuracy_score(train_labels_3, predictions)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'decision_tree_model.pkl'\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(tree_clf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
